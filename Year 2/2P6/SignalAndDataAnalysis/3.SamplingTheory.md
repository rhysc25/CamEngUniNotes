Modern system store and process signals in digital form, so signals must be converted from continuous time to discrete time. We do this through sampling, or analogue to digital conversion (ADC)
We want to take a sample at interval T, giving us the values $f(nT)$ where $n = -\infty,...,-1,0,1,...,\infty.$

Too large a value of T will mean loss of detail from $f(t)$ and aliasing
Oversampling will require too much data storage and will be computationally inefficient

The Sampling Theorem tells us the maximum value of T we can take and still perfectly reconstruct $f(t)$ from $f(nT)$

We can think of this as multiplying our signal by an infinite periodic impulse train
$f_s(t)=\sum_{-\infty}^{\infty} f(t) \delta(t-nT) = f(t)\delta_p (t)$
The signal $f_s(t)$ is a continuous-time signal that contains information only at the sample times $t=nT$ and is zero everywhere else

The impulse train has complex Fourier series coefficients $1/T$ for all $n$
This means that $f_s(t)=\frac{1}{T}\sum_{-\infty}^{\infty}f(t)e^{jn\omega_0 t}$
Performing a simple FT we get $F_s(\omega) = \frac{1}{T}\sum_{-\infty}^{\infty} F(\omega - n\omega_0)$

Sampling causes spectral repetition. The spectrum of the sampled signal is:
* A scaled version of the original spectrum
* Repeated every multiple of the sample frequency
* And summed
We can only perfectly reconstruct if our signals don't overlap, or else information is lost
If these copies overlap, aliasing occurs

Another way of reaching the DTFT is straight from the function of samples $f_s(t)$
$$F_s=\sum_{n=-\infty}^{\infty}f(nT)e^{-jm\omega T}$$
The Nyquist sampling theorem:
If a signal $f(t)$ has a maximum frequency content (or bandwidth) $\omega_{max}$, then it is possible to reconstruct $f(t)$ perfectly from its sampled version $f_s(t)$ provided the sampling rate is at least $\omega_0=2\omega_{max}$, the Nyquist frequency

The period repetitions of $F(\omega)$ in $F_s(\omega)$ are called aliasing. Sampling below $\omega_{Nyq}$ causes aliasing distortion, due to overlapping spectra.

**Reconstruction**
For perfect reconstruction, the frequency response of the ideal reconstruction filter must extract exactly one copy of the spectrum $H_r(\omega)= T$ for $-\omega_{max}<\omega<+\omega_{max}$ and 0 otherwise

The impulse response of this filter is given by the inverse Fourier transform of $H_r(\omega)$
Since the inverse FT of a rectangular pulse is a sinc function:
$h_r(t)=\frac{\omega_{max}T}{\pi}\text{sinc}(\omega_{max}T)=\text{sinc}(\frac{\omega_0 t}{2})$

Since multiplication in the frequency domain corresponds to convolution in the time domain, we must compute: $f(t)=\text{sinc}(\frac{\omega_0t}{2})*f_s(t)$
Substituting the expression for $f_s(t)$ and changing the order of integration and summation gives$$f(t)=\sum_{-\infty}^{\infty}f(nT)\text{sinc}(\frac{\pi}{T}(t-nT))$$
This is an exact interpolation formula for reconstructing $f(t)$ from its samples $f(nT)$

If we were doing this process for real we would also apply an anti-aliasing filter with frequency response $H_r(\omega)/T$ to remove high frequency noise and unwanted components

**Challenges in Practical Implementation**
Ideal low-pass filter are not physically realisable, real filters always have a transition band. To allow for roll off, a practical design includes an additional 10% bandwidth margin

In practice, there are two reasons why we can't compute the DTFT of a signal:
1) We don't have access to all of the data points from $-\infty$ to $+\infty$
2) $F_s(\omega)$ is defined over the continuous range of frequencies from $-\infty$ to $+\infty$, so it impossible to calculate and store $F_s(\omega)$ for all frequency values.

For these reasons, we instead use the discrete Fourier transform (DFT) as a way to bypass these practical difficulties.
If instead of infinite samples, we just keep N samples. $F_N(\omega)=\sum_{n=0}^{N-1}f(nT)e^{-jm\omega T}$
Sampling one period on the grid: $\omega_k = \frac{k\omega_0}{N}, F_k = F_N(\omega_k)$

If we capture a sufficiently long segment of the continuous signal, the truncates DTFT closely approximates the full DTFT

Since $F_N(\omega)$ is periodic with period $\omega_0$, it is sufficient to sample one period 
Given N data points, we sample at N evenly spaced frequencies: $\omega_m = m\frac{\omega_0}{N}, \quad m=0,1,2,...,N-1$

This leads to the full DFT: $$F_m=\sum_{n=0}^{N-1}f_ne^{-jnm2\pi / N}$$
$F_m$ are samples of the truncated spectrum $F_n(\omega)$ at $\omega_m=m\omega_0 / N$
$f_n=f(nT)$ represents sampled time-domain values

The DFT is actually computable. It is also periodic, so $F_{k+N}=F_k$.
For real-values signals: $F_{N-k}=F_k^*$

**The IDFT**
To find the inverse DFT, we multiply both sides by $e^{j2\pi km / N}$, then sum over $m=0$ to $m = N-1$
$\sum_{m=0}^{N-1}F_me^{j2\pi km/N}=\sum_{n=0}^{N-1}f_n\sum_{m=0}^{N-1}e^{j2\pi m (k-n) / N}$

The inner summation is a geometric progression of exponentials and can be shown that it is 0 if k not equal to n, but $N$ if $k=n$.
Therefore we end up with: $\sum_{m=0}^{N-1}F_me^{j2\pi km/N}=Nf_k$, and dividing by N we get the inverse DFT: $$f_k = \frac{1}{N}\sum_{m=0}^{N-1}F_me^{j2\pi km/N}$$
The DFT and the IDFT both have $O(N^2)$ time complexity as each output frequency component involves a sum over all N time-domain samples, meaning computationally inefficient. 
To address this in practice we use a Fast Fourier Transform (FFT) which reduces the time complexity to $O(N\log_2 N)$, significantly improving performance

Taking a finite set of samples can introduce discontinuities at the start and the end of the data frame, which results in spurious high frequency components. To reduce this effect we use a window function, which tapers smoothly to zero near $n=0 \text{and} n=N-1$
$f_w[n]=f[n]w[n]$
Different window shapes trade off spectral leakage against frequency resolution

Summary:
![[Pasted image 20260213124442.png]]
Sampling in time gives periodicity in frequency (DTFT)
Truncation in time gives discretisation in frequency (DFT)